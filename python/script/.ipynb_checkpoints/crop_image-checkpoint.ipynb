{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = glob.glob('../data/raw_image/*')\n",
    "raw_image_list = []\n",
    "image_array_list = []\n",
    "for file_path in path_list:\n",
    "    img = image.load_img(file_path)\n",
    "    image_array = preprocess_input(np.expand_dims(image.img_to_array(img.resize((256, 256))), axis=0))\n",
    "\n",
    "    raw_image_list.append(image.img_to_array(img))\n",
    "    image_array_list.extend(image_array)\n",
    "    \n",
    "x_image = np.array(image_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'nearest': pil_image.NEAREST\n",
    "# 'bilinear': pil_image.BILINEAR\n",
    "# 'bicubic': pil_image.BICUBIC\n",
    "# from PIL import Image as pil_image\n",
    "# img.resize((4032, 3024), pil_image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 256, 256, 3) (31, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "train_size = (256, 256, 3)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 3, activation='relu', padding='same', input_shape=train_size))\n",
    "model.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
    "model.add(Conv2D(1, 5, activation='sigmoid', padding='same'))\n",
    "\n",
    "model = model_from_json(open('../model/FE15_screen_model.json').read())\n",
    "model.load_weights('../model/FE15_screen_model_weights.h5')\n",
    "\n",
    "y_pred = model.predict(x_image)\n",
    "\n",
    "print(x_image.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(p1, p2):\n",
    "    return (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2\n",
    "\n",
    "def find_nearest_coord(x, point):\n",
    "    result_list = []\n",
    "    for p in x:\n",
    "        d = calc_distance(point, p)\n",
    "        result_list.append(d)\n",
    "    nearest_coord = x[np.argmin(result_list)]\n",
    "    point = x[np.argmin(result_list)]\n",
    "    point[0] = point[0] * (4032.0 / 256.0)\n",
    "    point[1] = point[1] * (3024.0 / 256.0)\n",
    "    return point\n",
    "\n",
    "def find_coner_coords(y_pred):\n",
    "    corner_size = 256\n",
    "    gray = y_pred.astype(np.uint8) * 255\n",
    "    \n",
    "    # Find contours\n",
    "    _, contours, hierarchy = cv2.findContours(gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    ul = find_nearest_coord(np.squeeze(contours[0], axis=1), [0, 0])\n",
    "    ur = find_nearest_coord(np.squeeze(contours[0], axis=1), [corner_size, 0])\n",
    "    lr = find_nearest_coord(np.squeeze(contours[0], axis=1), [corner_size, corner_size])\n",
    "    ll = find_nearest_coord(np.squeeze(contours[0], axis=1), [0, corner_size])\n",
    "    return np.array([ul, ur, lr, ll])\n",
    "\n",
    "def find_screen(x, points):\n",
    "    imgcont = x.copy()\n",
    "    cv2.polylines(imgcont, [points], True, (255, 255, 255), 2)\n",
    "    return image.array_to_img(imgcont)\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped\n",
    "\n",
    "file_index = 0\n",
    "for x_i ,y_p in zip(raw_image_list, y_pred):\n",
    "    points = find_coner_coords(y_p > 0.95)\n",
    "    save_path = '../data/pure_game_screen/{}.jpg'.format(str(file_index).zfill(4))\n",
    "    image.array_to_img(four_point_transform(x_i, points)).save(save_path)\n",
    "    file_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

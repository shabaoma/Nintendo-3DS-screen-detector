{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file '../data/raw_image/IMG_4477.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-efcdca999887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbatch_resize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-efcdca999887>\u001b[0m in \u001b[0;36mbatch_resize_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/raw_image/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/resized_image/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/venv/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    385\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    386\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/venv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2590\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file '../data/raw_image/IMG_4477.jpg'"
     ]
    }
   ],
   "source": [
    "# resize image\n",
    "def show_image(array):\n",
    "    display(image.array_to_img(array))\n",
    "\n",
    "def batch_resize_image():\n",
    "    image_list = glob.glob('../data/raw_image/*')\n",
    "    for image_path in image_list:\n",
    "        img = image.load_img(image_path, target_size=(image_size, image_size))\n",
    "        img.save('../data/resized_image/{}'.format(os.path.basename(image_path)))\n",
    "\n",
    "image_size = 256\n",
    "batch_resize_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_coord\n",
    "import json\n",
    "\n",
    "def get_coords(x):\n",
    "    coord_json = json.loads(x)\n",
    "    result_list = []\n",
    "    for geometry in coord_json['Corner of Building']:\n",
    "        result_list.append([geometry['geometry']['x'], geometry['geometry']['y']])\n",
    "    return result_list\n",
    "\n",
    "def calc_distance(p1, p2):\n",
    "    return (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2\n",
    "\n",
    "def find_nearest_coord(x, point):\n",
    "    result_list = []\n",
    "    for p in x:\n",
    "        d = calc_distance(point, p)\n",
    "        result_list.append(d)\n",
    "    nearest_coord = x[np.argmin(result_list)]\n",
    "    return x[np.argmin(result_list)]\n",
    "\n",
    "def reformat_coord(df, image_size):\n",
    "    tmp_list = []\n",
    "    for point in df.values:\n",
    "        [tmp_list.append(coord / image_size) for coord in point]\n",
    "    return tmp_list\n",
    "\n",
    "# 手动标注端点坐标的图片大小为512\n",
    "# last_index = 511\n",
    "# coord_df = pd.read_csv('../data/coner_coord/export-2019-02-08T05_15_26.966Z.csv')[['External ID', 'Label']]\n",
    "# coord_df['coords'] = coord_df['Label'].apply(lambda x: get_coords(x))\n",
    "# coord_df['ul'] = coord_df['coords'].apply(lambda x: find_nearest_coord(x, [0, 0]))\n",
    "# coord_df['ur'] = coord_df['coords'].apply(lambda x: find_nearest_coord(x, [last_index, 0]))\n",
    "# coord_df['lr'] = coord_df['coords'].apply(lambda x: find_nearest_coord(x, [last_index, last_index]))\n",
    "# coord_df['ll'] = coord_df['coords'].apply(lambda x: find_nearest_coord(x, [0, last_index]))\n",
    "# coord_df[['ul', 'ur', 'lr', 'll']].to_csv('../data/coner_coord/y_coords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_mask\n",
    "def batch_get_mask(coord_df):\n",
    "    dimension = 1\n",
    "    result_list = []\n",
    "    for i in range(len(coord_df)):\n",
    "        image_path = '../data/resized_image/{}'.format(coord_df.iloc[i]['External ID'])\n",
    "        mask_path = '../data/resized_mask/{}'.format(coord_df.iloc[i]['External ID'])\n",
    "        points = coord_df.iloc[i][['ul', 'ur', 'lr', 'll']].values\n",
    "        \n",
    "        if dimension == 1:\n",
    "            single_image = np.zeros((corner_size, corner_size, dimension))\n",
    "        else:\n",
    "            single_image = image.load_img(image_path)\n",
    "            single_image = image.img_to_array(single_image)\n",
    "        cv2.fillConvexPoly(single_image, np.array([point for point in points]), (255) if dimension == 1 else (255, 255, 255))\n",
    "        \n",
    "        new_size = 256\n",
    "        img = image.array_to_img(single_image)\n",
    "        img = img.resize((new_size, new_size))\n",
    "        img.save(mask_path)\n",
    "        # display(img)\n",
    "\n",
    "batch_get_mask(coord_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate more image and mask\n",
    "image_list = glob.glob('../data/resized_image/*')\n",
    "mask_list = glob.glob('../data/resized_mask/*')\n",
    "image_result = []\n",
    "mask_result = []\n",
    "for image_path, mask_path in zip(image_list, mask_list):\n",
    "    image_result.append(image.img_to_array(image.load_img(image_path)))\n",
    "    mask_result.append(image.img_to_array(image.load_img(mask_path, grayscale=True)))\n",
    "image_result = np.array(image_result)\n",
    "mask_result = np.array(mask_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.061 1.0\n",
      "(640, 256, 256, 3) (640, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# generate more image and mask\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "image_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 5, \n",
    "                  width_shift_range = 0.01, \n",
    "                  height_shift_range = 0.01, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.1],  \n",
    "                  horizontal_flip = False, \n",
    "                  vertical_flip = False,\n",
    "                  fill_mode = 'nearest',\n",
    "                  data_format = 'channels_last',\n",
    "                  preprocessing_function = preprocess_input\n",
    "                 )\n",
    "mask_args = image_args.copy()\n",
    "mask_args['preprocessing_function'] = lambda x: x / 255.0\n",
    "image_datagen = ImageDataGenerator(**image_args)\n",
    "mask_datagen = ImageDataGenerator(**mask_args)\n",
    "\n",
    "seed = 2\n",
    "batch_size = 20\n",
    "image_flow_args = dict(x = image_result,\n",
    "                       batch_size = batch_size, \n",
    "                       shuffle = True, \n",
    "                       seed = seed)\n",
    "mask_flow_args = dict(x = mask_result,\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      seed = seed)\n",
    "\n",
    "loop_count = 0\n",
    "file_index = 0\n",
    "gen_image_result = []\n",
    "gen_mask_result = []\n",
    "for new_images, new_masks in zip(image_datagen.flow(**image_flow_args), mask_datagen.flow(**mask_flow_args)):\n",
    "    gen_image_result.extend(new_images)\n",
    "    gen_mask_result.extend(new_masks)\n",
    "\n",
    "    for new_image, new_mask in zip(new_images, new_masks):\n",
    "        img = image.array_to_img(new_image)\n",
    "        mask = image.array_to_img(new_mask)\n",
    "        img.save('../data/gen_image/{}.jpg'.format(str(file_index).zfill(4)))\n",
    "        mask.save('../data/gen_mask/{}.jpg'.format(str(file_index).zfill(4)))\n",
    "        file_index += 1\n",
    "        \n",
    "    if loop_count >= 40:\n",
    "        break\n",
    "    loop_count += 1\n",
    "    \n",
    "gen_image_result = np.array(gen_image_result)\n",
    "gen_mask_result = np.array(gen_mask_result)\n",
    "print(gen_image_result.max(), gen_mask_result.max())\n",
    "print(gen_image_result.shape, gen_mask_result.shape)\n",
    "np.save('../data/cnn_data/x.npy', gen_image_result)\n",
    "np.save('../data/cnn_data/y_256.npy', gen_mask_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把y做的更小\n",
    "# target_size = 64\n",
    "# resized_y_list = []\n",
    "# for y in data_y:\n",
    "#     resized_y_list.append(image.img_to_array(image.array_to_img(y).resize((target_size, target_size))))\n",
    "# resized_y_array = np.array(resized_y_list) / 255.0\n",
    "# print(resized_y_array.shape, resized_y_array.max())\n",
    "# np.save('../data/cnn_data/y_{}.npy'.format(target_size), resized_y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(256, 256, 1) (256, 256, 1)\n",
      "(256, 256, 1)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(256, 256, 1) (256, 256, 1)\n",
      "(256, 256, 1)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(256, 256, 1) (256, 256, 1)\n",
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# # resized_image的四角坐标\n",
    "# def get_corner_coords_from_mask(target_array):\n",
    "#     dst = cv2.dilate(cv2.cornerHarris(target_array,2,3,0.04),None)\n",
    "#     item_index = np.where(dst>0.1*dst.max())\n",
    "#     item_index_array = np.concatenate([np.expand_dims(item_index[1], axis=-1), np.expand_dims(item_index[0], axis=-1)], axis=1)\n",
    "#     ul = item_index_array[np.argmin([calc_distance(x, [0, 0]) for x in item_index_array])]\n",
    "#     ur = item_index_array[np.argmin([calc_distance(x, [0, last_index]) for x in item_index_array])]\n",
    "#     lr = item_index_array[np.argmin([calc_distance(x, [last_index, last_index]) for x in item_index_array])]\n",
    "#     ll = item_index_array[np.argmin([calc_distance(x, [last_index, 0]) for x in item_index_array])]\n",
    "#     return [ul[0], ul[1], ur[0], ur[1], lr[0], lr[1], ll[0], ll[1]]\n",
    "    \n",
    "# last_index = 255\n",
    "# data_y = np.load('../data/cnn_data/y_256.npy')\n",
    "# resized_image_coords = np.array([get_corner_coords_from_mask(target_array) for target_array in data_y]) / 255.0\n",
    "# np.save('../data/cnn_data/y_{}_coords.npy'.format(256), resized_image_coords)\n",
    "\n",
    "for i in range(3):\n",
    "    y_true_mask = data_y[i]\n",
    "#     show_image(y_true_mask)\n",
    "    \n",
    "    y_pred = resized_image_coords[i]\n",
    "    points = np.array([[int(y_pred[0]*255.0),int(y_pred[1]*255.0)], \n",
    "                       [int(y_pred[2]*255.0),int(y_pred[3]*255.0)], \n",
    "                       [int(y_pred[4]*255.0),int(y_pred[5]*255.0)], \n",
    "                       [int(y_pred[6]*255.0),int(y_pred[7]*255.0)]])\n",
    "    y_pred_mask = np.zeros((256, 256, 1)).astype(np.float32)\n",
    "    cv2.fillConvexPoly(y_pred_mask, points, (1))\n",
    "#     show_image(y_pred_mask)\n",
    "\n",
    "    print(type(y_true_mask), type(y_pred_mask))\n",
    "    print(y_true_mask.shape, y_pred_mask.shape)\n",
    "    print((y_true_mask * y_pred_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
